{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code builds out models for pickle files\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "g_cv = \"\"\n",
    "g_model = \"\"\n",
    "\n",
    "\n",
    "# controls workflow of this executable\n",
    "def main():\n",
    "    os.chdir(\"C:\\\\Users\\\\jdale\\\\OneDrive\\\\School\\\\Text Analytics\\\\the_analyzer\")\n",
    "    df = parse_yummly()\n",
    "    create_model_from_df_cuisine(df)\n",
    "\n",
    "\n",
    "# opens and parses local yummly json file\n",
    "def parse_yummly():\n",
    "    with open('yummly.json', 'rb') as file:\n",
    "        file_json = json.load(file)\n",
    "        df = create_dataframe(file_json)\n",
    "        file.close()\n",
    "        return df\n",
    "\n",
    "\n",
    "# creates a pandas dataframe from the yummly json file that contains three columns: 1. id 2. cuisine 3. ingredients\n",
    "def create_dataframe(file):\n",
    "    id_list = list()\n",
    "    cuisine_list = list()\n",
    "    ingredient_list = list()\n",
    "    for recipe in file:\n",
    "        id_list.append(recipe['id'])\n",
    "        cuisine_list.append(recipe['cuisine'])\n",
    "        ing_string = \"\"\n",
    "        for ing in recipe['ingredients']:\n",
    "            ing_string = ing_string + \" \" + ing\n",
    "        ingredient_list.append(ing_string)\n",
    "    data = {'id': id_list,\n",
    "            'cuisine': cuisine_list,\n",
    "            'ingredients': ingredient_list}\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# not used in final implementation\n",
    "def format_cuisine(cuisine_dictionary, cuisine_list):\n",
    "    ingredient_dictionary = dict()\n",
    "    for cuisine in cuisine_list:\n",
    "        ingredient_string = \"\"\n",
    "        ingredient_list = cuisine_dictionary[cuisine]\n",
    "        for ingredient in ingredient_list:\n",
    "            ingredient_string = ingredient_string + ingredient\n",
    "        ingredient_dictionary[cuisine] = ingredient_string\n",
    "    return ingredient_dictionary\n",
    "\n",
    "\n",
    "# not used in final implementation\n",
    "def label(df):\n",
    "    cuisine_list = df.cuisine.unique()\n",
    "    count_label = 0\n",
    "    id_list = list()\n",
    "    cuisine_list2 = list()\n",
    "    ingredient_list = list()\n",
    "    label_list = list()\n",
    "    cuisine_label_dict = dict()\n",
    "    for cuisine in cuisine_list:\n",
    "        cuisine_label_dict[cuisine] = count_label\n",
    "        count_label = count_label + 1\n",
    "    for index, row in df.iterrows():\n",
    "        id_list.append(row['id'])\n",
    "        cuisine_list2.append(row['cuisine'])\n",
    "        ingredient_list.append(row['ingredients'])\n",
    "        label_list.append(cuisine_label_dict[row['cuisine']])\n",
    "    data = {'id': id_list,\n",
    "            'cuisine': cuisine_list2,\n",
    "            'ingredients': ingredient_list,\n",
    "            'label': label_list}\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# tokenizes the ingredients and creates a SVC model for the cuisine types\n",
    "def create_model_from_df_cuisine(df):\n",
    "    x_train = df['ingredients']\n",
    "    y_train = df['cuisine']\n",
    "    cv = CountVectorizer()\n",
    "    x_train_cv = cv.fit_transform(x_train)\n",
    "    ttt = TfidfTransformer()\n",
    "    x_train_ttt = ttt.fit_transform(x_train_cv)\n",
    "    clf = SVC(gamma = 'auto', probability=True).fit(x_train_ttt, y_train)\n",
    "\n",
    "    pickle_save1 = 'pickle_cv.pkl'\n",
    "    pickle.dump(cv, open(pickle_save1, 'wb'))\n",
    "    g_cv = cv\n",
    "    pickle_save = 'pickle_model.pkl'\n",
    "    g_model = clf\n",
    "    pickle.dump(clf, open(pickle_save,  'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from train_analyzer_from_yummly import parse_yummly\n",
    "import jellyfish\n",
    "import sys\n",
    "\n",
    "# provides support for all functions called within main.py\n",
    "\n",
    "\n",
    "# takes argparse of ingredients and appends them all into one string that can be analyzed by learning models\n",
    "def ingredients_to_string(ingredients_list):\n",
    "    ingredients_string = \"\"\n",
    "    for ingredient in ingredients_list.ingredient:\n",
    "        ingredients_string = ingredients_string + ingredient + ' '\n",
    "    return ingredients_string\n",
    "\n",
    "\n",
    "# takes ingredients string and shows the predicted cuisine and the predicted value of the cuisine type\n",
    "def predict_cuisine(ingredients):\n",
    "    clf = pickle.load(open('pickle_model.pkl', 'rb'))\n",
    "    cv = pickle.load(open('pickle_cv.pkl', 'rb'))\n",
    "    values = clf.predict_proba(cv.transform([ingredients]))\n",
    "    df = create_probability_dataframe(values, clf.classes_)\n",
    "    cuisine_df = get_top_n_from_df(df, 1)\n",
    "    cuisine_confidence = float(round(cuisine_df.value * 100, 2))\n",
    "    recipe_confidence = recipe_finder(ingredients, 5)\n",
    "    print('Cuisine: ', cuisine_df.cuisine.iat[0].capitalize(), ' (', cuisine_confidence, '%)', sep='')\n",
    "    print(recipe_confidence)\n",
    "\n",
    "\n",
    "# formats value list and class list into a pandas dataframe that can more easily be analyzed for top values\n",
    "def create_probability_dataframe(value_list, class_list):\n",
    "    v_list = list()\n",
    "    c_list = list()\n",
    "    data = {'value': value_list[0],\n",
    "            'cuisine': class_list}\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# retrieve the top n best columns based on model score\n",
    "def get_top_n_from_df(df, n):\n",
    "    largest = df.nlargest(n, 'value')\n",
    "    return largest\n",
    "\n",
    "\n",
    "# given the input ingredients, finds the top n most similar recipes from yummly\n",
    "def recipe_finder(ingredients, n):\n",
    "    df = parse_yummly()\n",
    "    ingredients_list = set(ingredients.split())\n",
    "    match_number = 0\n",
    "    id_score_dict = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        row_i_list = set(row['ingredients'].split())\n",
    "        for ingredient in ingredients_list:\n",
    "            for i in row_i_list:\n",
    "                if ingredient == i:\n",
    "                    match_number += 1\n",
    "        match_percentage = match_number / len(ingredients_list)\n",
    "        match_number = 0\n",
    "        id_score_dict[row['id']] = match_percentage\n",
    "    final_string = \"Closest \" + str(n) + \" recipes: \"\n",
    "    for key in {key: id_score_dict[key] for key in sorted(id_score_dict, key=id_score_dict.get, reverse=True)[:n]}:\n",
    "        value = ({key: id_score_dict[key] for key in sorted(id_score_dict, key=id_score_dict.get, reverse=True)[:n]}[key])\n",
    "        final_string = final_string + str(key) + ' ' + '(' + str(round(value * 100, 2)) + '%) '\n",
    "    return final_string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "#import project_3\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "# takes arguments from argparse coming from --ingredient to process ingredients into a list\n",
    "# that can be analyzed by learning models to predict cuisine type and N closest recipes\n",
    "def main(arguments):\n",
    "    ingredients = ingredients_to_string(arguments)\n",
    "    predict_cuisine(ingredients)\n",
    "\n",
    "\n",
    "# runs via: \"py main.py --ingredient granola --ingredient rice\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# all possible arguments defined with help\n",
    "parser.add_argument(\"--ingredient\", action='append', type=str, required=True,\n",
    "                    help=\"ingredient for cooking!\")\n",
    "args = parser.parse_args([\"--ingredient\", \"sauce\",\n",
    "                          \"--ingredient\", \"peanuts\",\n",
    "                          \"--ingredient\", \"tofu\",\n",
    "                          \"--ingredient\", \"rice\"])\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
